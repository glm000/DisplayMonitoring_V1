import cv2
import numpy as np
import time


class ScreenMonitor:
    def __init__(self, black_threshold=10, freeze_threshold=1.0):
        """
        åˆå§‹åŒ–ç›‘æµ‹å™¨
        :param black_threshold: é»‘å±åˆ¤å®šé˜ˆå€¼
        :param freeze_threshold: å¡æ­»/è§¦æ§åˆ¤å®šé˜ˆå€¼
        """
        self.black_threshold = black_threshold
        self.freeze_threshold = freeze_threshold
        self.last_frame = None  # ç”¨æ¥å­˜å‚¨ä¸Šä¸€å¸§ï¼Œç”¨äºå¯¹æ¯”å¡æ­»

    def check_black_screen(self, image):
        """æ£€æµ‹å½“å‰å¸§æ˜¯å¦é»‘å±"""
        if image is None:
            return False, "å›¾åƒä¸ºç©º"

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        avg_val = np.mean(gray)

        if avg_val < self.black_threshold:
            return True, f"æ£€æµ‹åˆ°é»‘å± (äº®åº¦: {avg_val:.2f})"
        return False, "å±å¹•æ­£å¸¸"

    def check_freeze(self, current_image):
        """æ£€æµ‹ç”»é¢æ˜¯å¦ç›¸å¯¹äºä¸Šä¸€å¸§å¡æ­»"""
        if self.last_frame is None:
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œæ²¡æœ‰ä¸Šä¸€å¸§ï¼Œå°±å…ˆå­˜ä¸‹æ¥ï¼Œè·³è¿‡æ£€æµ‹
            self.last_frame = current_image
            return False, "åˆå§‹åŒ–å¸§ (æ— å¯¹æ¯”æ•°æ®)"

        # 1. è½¬ç°åº¦
        gray1 = cv2.cvtColor(self.last_frame, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)

        # 2. ç¡®ä¿å°ºå¯¸ä¸€è‡´
        if gray1.shape != gray2.shape:
            # å¦‚æœå°ºå¯¸å˜äº†ï¼Œé‡ç½®ä¸Šä¸€å¸§
            self.last_frame = current_image
            return False, "åˆ†è¾¨ç‡æ”¹å˜ï¼Œé‡ç½®å¯¹æ¯”å¸§"

        # 3. è®¡ç®—å·®å¼‚
        diff = cv2.absdiff(gray1, gray2)
        score = np.mean(diff)

        # æ›´æ–°ä¸Šä¸€å¸§ (ä¸ºä¸‹ä¸€æ¬¡æ£€æµ‹åšå‡†å¤‡)
        self.last_frame = current_image

        if score < self.freeze_threshold:
            return True, f"æ£€æµ‹åˆ°ç”»é¢å¡æ­» (å˜åŒ–åº¦: {score:.4f})"
        else:
            return False, f"ç”»é¢æ­£å¸¸è¿è¡Œ (å˜åŒ–åº¦: {score:.4f})"

    def verify_touch(self, image_before, image_after):
        """éªŒè¯è§¦æ§åŠ¨ä½œ (å¯¹æ¯”ç‚¹å‡»å‰å)"""
        # å¤ç”¨ä¸Šé¢çš„å¡æ­»æ£€æµ‹é€»è¾‘ï¼Œä½†å«ä¹‰ç›¸å
        # è§¦æ§æˆåŠŸ = ç”»é¢æœ‰å˜åŒ– (score > threshold)

        gray1 = cv2.cvtColor(image_before, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(image_after, cv2.COLOR_BGR2GRAY)

        if gray1.shape != gray2.shape:
            return False, "å°ºå¯¸ä¸ä¸€è‡´"

        diff = cv2.absdiff(gray1, gray2)
        score = np.mean(diff)

        if score > self.freeze_threshold:
            return True, f"è§¦æ§æˆåŠŸ (å˜åŒ–åº¦: {score:.4f})"
        else:
            return False, f"è§¦æ§å¤±æ•ˆ/æ— å“åº” (å˜åŒ–åº¦: {score:.4f})"


# --- ä¸»ç¨‹åºè¿è¡Œé€»è¾‘ (æ¨¡æ‹Ÿ) ---
if __name__ == "__main__":
    # 1. å¯åŠ¨ç›‘æµ‹å‘˜
    monitor = ScreenMonitor(black_threshold=10, freeze_threshold=1.0)

    print("ğŸš€ å±å¹•ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨...\n")

    # æ¨¡æ‹Ÿè¯»å–åˆ°çš„å›¾ç‰‡åºåˆ— (ä½ å¯ä»¥æ¢æˆæ‘„åƒå¤´ cap.read())
    # å‡è®¾ï¼šç¬¬ä¸€ç§’æ­£å¸¸ï¼Œç¬¬äºŒç§’é»‘å±ï¼Œç¬¬ä¸‰ç§’å¡æ­»
    test_files = ['test_b.jpg', 'test_b.jpg', 'test_w.jpg']

    # 2. æ¨¡æ‹Ÿå¾ªç¯æ£€æµ‹
    for i, file_name in enumerate(test_files):
        print(f"--- ç¬¬ {i+1} æ¬¡æ£€æµ‹ ({file_name}) ---")

        # è¯»å–å½“å‰å¸§
        frame = cv2.imread(file_name)
        if frame is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {file_name}")
            continue

        # [æ­¥éª¤ A] å…ˆæŸ¥é»‘å±
        is_black, msg_black = monitor.check_black_screen(frame)
        if is_black:
            print(f"ğŸš¨ ä¸¥é‡æ•…éšœ: {msg_black}")
            # å¦‚æœé»‘å±äº†ï¼Œé€šå¸¸å°±ä¸éœ€è¦æµ‹å¡æ­»äº†ï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€è½®
            continue

        # [æ­¥éª¤ B] å†æŸ¥å¡æ­» (éœ€è¦å’Œä¸Šä¸€æ¬¡çš„å›¾ç‰‡å¯¹æ¯”)
        is_frozen, msg_freeze = monitor.check_freeze(frame)
        if is_frozen:
            print(f"âš ï¸ è­¦å‘Š: {msg_freeze}")
        else:
            print(f"âœ… {msg_freeze}")

        time.sleep(1)  # æ¨¡æ‹Ÿé—´éš”

    # [æ­¥éª¤ C] å•ç‹¬æµ‹è¯•è§¦æ§ (å½“æœºå™¨è‡‚æ‰§è¡Œç‚¹å‡»åŠ¨ä½œæ—¶è°ƒç”¨)
    print("\n--- è§¦å‘æµ‹è¯•: ç‚¹å‡»åŠ¨ä½œéªŒè¯ ---")
    # ä¼ å…¥ä¸¤å¼ å›¾ï¼šç‚¹å‡»å‰ï¼Œç‚¹å‡»å
    success, msg_touch = monitor.verify_touch(
        cv2.imread('test_b.jpg'), cv2.imread('test_w.jpg'))
    print(f"ğŸ‘‰ è§¦æ§æµ‹è¯•ç»“æœ: {msg_touch}")
